# ğŸ§  Breast Cancer Malignancy Prediction using CLIP

**Capstone Project II â€“ DSCI 592 (Spring 2025)**  
This repository is part of the final submission for **Capstone Project II** coursework at Drexel University, focused on applying Vision-Language Models (VLMs) to medical imaging tasks.

We develop a custom classification pipeline using **OpenAIâ€™s CLIP (ViT-B/32)** model and a custom Fully Connected classifier to predict breast cancer malignancy based on mammogram images. The project leverages advanced preprocessing, embedding refinement, and prompt engineering to improve interpretability and accuracy.

> ğŸ“Œ **Core Contribution by Author**  
> The following notebooks were entirely developed in-house:
> - `CLIP_Modelv1.ipynb`
> - `PreProcessingBasicModel.ipynb`
> - `PreProcessing_with_basicmodels.ipynb`
> - `breast-cancer-eda.ipynb`
> - `data_clean_eda.ipynb`  
>  Other scripts and models are included for support and comparison purposes.
```
.
â”œâ”€â”€ CLIP_Modelv1.ipynb # Custom SimilarityFCClassifier using CLIP embeddings
â”œâ”€â”€ PreProcessingBasicModel.ipynb # Preprocessing pipeline, path correction, image mapping
â”œâ”€â”€ PreProcessing_with_basicmodels.ipynb# Preprocessing + baseline models (e.g., logistic regression)
â”œâ”€â”€ breast-cancer-eda.ipynb # Exploratory data analysis (EDA)
â”œâ”€â”€ data_clean_eda.ipynb # Metadata cleaning and alignment
â”œâ”€â”€ DSCI 592 - Pitch PPT.pptx.pdf # Project pitch presentation
â”œâ”€â”€ S_MasterProject_Proposal_v2.docx # Project proposal document
â”œâ”€â”€ README.md # This file
â”œâ”€â”€ ex1.png # Sample image
â”œâ”€â”€ open_clip_ex1.ipynb # External reference (OpenCLIP usage)
â”œâ”€â”€ torch_clip.ipynb # External reference (Torch CLIP example)
â”œâ”€â”€ CLIP_for_Breast_Cancer_TF.ipynb # External support (TensorFlow-based CLIP example)
â”œâ”€â”€ CLIP_TF_CNN_Transformer.ipynb # External support (CNN-Transformer hybrid)
```
---

## ğŸ“Š Dataset: CBIS-DDSM

> Source: [TCIA CBIS-DDSM](https://wiki.cancerimagingarchive.net/display/Public/CBIS-DDSM)

- **Full Mammograms**: 2,857 images
- **Cropped ROIs**: 3,567 images
- **ROI Segmentation Masks**: 3,247 binary masks
- **Metadata**: BI-RADS scores, shape, margin, pathology labels (BENIGN/MALIGNANT), etc.

---

## âš™ï¸ Workflow Overview

### âœ… 1. Preprocessing (`PreProcessingBasicModel.ipynb`)
- Load and clean metadata from multiple CSVs
- Correct file paths and map UIDs
- Normalize and transform images (224Ã—224, CLIP input format)
- Stratified train/val/test split

### ğŸ“ˆ 2. Exploratory Data Analysis (`breast-cancer-eda.ipynb`)
- Visualize image dimensions, distribution, and modalities
- Analyze metadata patterns (shape, margin, BI-RADS)

### ğŸ§  3. Modeling (`CLIP_Modelv1.ipynb`)
- Extract 512-dim embeddings from CLIP ViT-B/32 (frozen)
- Build `SimilarityFCClassifier`: a 2-layer MLP that refines embeddings
- Use cosine similarity with descriptive text prompts as logits
- Train using `CrossEntropyLoss`

### âš–ï¸ 4. Evaluation
- Metrics: Accuracy, AUC, Precision, Recall, F1-Score
- Analyze threshold tuning for clinical use
- Compare with zero-shot CLIP and logistic regression

---

## ğŸ§ª Performance Summary

| Model              | Accuracy | AUC  | F1 Score |
|-------------------|----------|------|----------|
| Logistic Baseline | ~68.4%   | 0.74 | 0.66     |
| Zero-Shot CLIP    | 76.2%    | 0.81 | 0.75     |
| Custom FC Head    | 72.2%    | 0.788| 0.71     |
| OpenCLIP          | 89.4%    | 0.94 | 0.89     |

---
## ğŸ“· Visual Insights and Evaluation

Below are key visualizations and outputs from the project, highlighting data characteristics, model behavior, and performance across multiple dimensions.
### ğŸ“Š Image Dimension Distribution

To understand the dataset characteristics, we visualized the distribution of image dimensions using KDE plots.  
This shows the multimodal nature of image sizes, helping inform preprocessing choices like resizing.

![KDE Plot](./images/kde_plot.png)

### ğŸ“ Aspect Ratio Consistency

A scatter plot of image height vs. width confirms a strong linear correlation, indicating consistent aspect ratios across samples.  
This validates the resizing step in the preprocessing pipeline.

![Aspect Ratio Scatter](./images/aspect_ratio_scatter.png)

### ğŸ©» CBIS-DDSM Dataset Overview

The CBIS-DDSM dataset includes original mammograms, cropped ROIs, and segmentation masks.  
This figure shows examples of both benign and malignant cases across these views.

![CBIS-DDSM Samples](./images/cbis_ddsm_examples.png)

### ğŸ§  Training Progress â€“ Similarity-Guided Classifier

This figure shows the training logs of the best `SimilarityFCClassifier` configuration.  
Early stopping was triggered after 27 epochs, reaching a peak ROC AUC of ~0.79.

![Training Log](./images/fc_classifier_training_log.png)

### âš–ï¸ Decision Threshold Analysis

To tune for clinical use cases (e.g., screening vs. diagnosis), we evaluated model metrics at different thresholds.  
Lower thresholds improved malignant recall; higher ones improved benign precision.

![Threshold Analysis](./images/threshold_analysis_table.png)



## ğŸ” Highlights

- âœ… Vision-Language Learning using CLIP (frozen)
- âœ… Prompt engineering for medical classification
- âœ… Custom FC network trained via image-text similarity
- âœ… Preprocessing for >20,000+ paths using UID mapping
- âœ… Metadata-based error analysis

---

## ğŸš€ Future Work

- âœï¸ Add **ChatGPT-like justification generation** from image embeddings
- ğŸ”„ Fine-tune CLIP on mammogram-specific data
- ğŸ§  Introduce **Visual Question Answering (VQA)** capability
- âš–ï¸ Implement **Focal Loss** and **class-weight tuning** for imbalanced datasets

---

## ğŸ“š Report and Proposal

- ğŸ“„ [`FinalReport.pdf`](./FinalReport.pdf) â€“ Full methodology, EDA, model performance
- ğŸ§  [`S_MasterProject_Proposal_v2.docx`](./S_MasterProject_Proposal_v2.docx) â€“ Research scope
- ğŸ¤ [`DSCI 592 - Pitch PPT.pptx.pdf`](./DSCI%20592%20-%20Pitch%20PPT.pptx.pdf) â€“ Slide deck

---

## ğŸ‘¨â€ğŸ’» Author Contribution

Developed and maintained by **Ram Kishore KV** and collaborators.

- All code and analysis notebooks marked above were authored by Ram.
- External notebooks were added only for architectural comparison or extension references.

---

## ğŸ“„ License

This project is for academic and research use only. Reuse requires citation and permission.

---

## ğŸ“¬ Contact

Feel free to reach out via [GitHub](https://github.com/RamKishoreKV) or connect on LinkedIn for collaboration inquiries.
